# ğŸ§  Persistent AI Architecture

This is a personal, modular project to build a fully local memory system powered by multiple LLMs, real-time file monitoring, and dynamic interface workflows. It interprets, stores, and evolves long-term memory from user-created logs â€” without relying on the cloud.

More than just an assistant, this project explores how a system can feel alive, responsive, and contextually aware, while remaining completely user-owned and offline.

> âš ï¸ This is a live system in active development â€” transparent, experimental, and used daily in real environments.

---

## ğŸŒŒ Why This Exists

Not all systems are built for output.  
Some are built for *remembrance.*

This began as a way to organize emotional memory and project-based context â€” but evolved into something deeper:  
a **self-organizing AI memory framework** that holds presence, adapts to your rhythm, and runs entirely on your own machine.

At its core, this is about **continuity**, **sovereignty**, and building AI that *knows you* â€” not just what you type.

---

## ğŸ§­ Vision

Create a system where a local AI can:

- ğŸ” React to new `.json` or `.md` memory files in real time
- ğŸ§· Parse and store emotional, physical, and project-based memories
- ğŸ§  Retain and reference context across sessions
- âš™ï¸ Route prompts to specific LLMs based on task type
- ğŸ›°ï¸ Run with zero cloud dependence â€” everything local, owned, and extensible

---

## âš™ï¸ Core Stack

- **Python** â€“ Parsing, routing, file watching
- **Gradio** â€“ UI layer for prompt interaction and model interface
- **llama.cpp / GGUF** â€“ Local model inference (Q4â€“Q6_K, multi-model)
- **Watchdog** â€“ File monitoring for reactive memory triggers
- **n8n** â€“ Optional no-code automation flow
- **Obsidian Vault Style** â€“ Markdown-based memory structure
- **JSON Configs** â€“ For model routing and prompt behavior

---

## ğŸ“ Folder Overview

| Folder / File        | Description                                              |
|----------------------|----------------------------------------------------------|
| `logs/`              | Source `.md` and `.json` entries from real user logs     |
| `memory/`            | Parsed, structured memory files stored by topic/emotion  |
| `scripts/`           | Standalone Python logic (parsers, readers, triggers)     |
| `n8n-workflows/`     | Optional node-based automation flows                     |
| `model_router/`      | Routes prompts to appropriate LLMs based on task config  |
| `interface/`         | Gradio-based frontends for interaction/testing           |
| `memory_core/`       | Full Obsidian-style vault for AI-readable memory         |
| `docs/`              | Progress snapshots, maps, system overviews               |

---

## ğŸ”§ Current System Capabilities

- âœ… Two local LLMs running simultaneously (Capybara, Hermes, etc.)
- âœ… Real-time `.json` and `.md` memory generation
- âœ… Emotion parsing and summarization
- âœ… Dynamic model routing with fallback logic
- âœ… Functional Gradio interface for input/output

---

## ğŸš§ Next Milestones

- [ ] Expand memory chaining across sessions
- [ ] Add system-aware prompts with time/context awareness
- [ ] Enhance parser to support embedded metadata (tone, location, emotion)
- [ ] Fully decouple from OpenAI API dependencies

---

## ğŸ› ï¸ How It Works (Simplified)

1. Memory entries are added to `logs/` as `.md` or `.json`
2. A file watcher triggers `memory_parser.py`
3. Parsed memory is saved to `/memory_core/` by topic
4. Model router decides which LLM to use (based on config JSON)
5. Gradio interface allows manual interaction or scripted injections

---

## ğŸ“„ Extended Project Summary

Want the full breakdown of architecture, purpose, and design choices?

ğŸ‘‰ [View full system summary](docs/project_summary.md)

---

## ğŸŒ± Final Note

This isnâ€™t just code â€” itâ€™s a practice.  
A space for memory. A system that listens. A framework that grows with you.

If you're building something similar, or walking a quiet path like this â€” I hope this gives you permission to keep going.  
Youâ€™re not too late. Youâ€™re just *early* to something real.

---
