# ğŸ§  AI Memory Architecture

> A modular memory brain that parses emotional logs, processes them with local LLMs, and returns both structured `.json` and stylized `.md` memory summaries. This repo showcases a complete offline pipeline â€” from Obsidian-style memory input to enriched AI output.

---

## ğŸ“˜ Overview

This project simulates a **local AI memory system** that can:

* Parse and structure Markdown memory logs
* Run those logs through a multi-model chain (Capybara â†’ Hermes â†’ MythoMax)
* Output emotional summaries, tags, and narrative markdown logs
* Optionally voice the output using ElevenLabs (or local TTS)

---

## ğŸ§  Memory Flow Diagram

A visual overview of the full local-first memory architecture â€” from markdown log ingestion to multi-model enrichment and semantic retrieval.

![Memory Architecture Diagram](./memory_flow_diagram_dark.png) (./memory_flow_diagram_dark.png)

---

## ğŸ§‰ Project Features

* ğŸ”„ Markdown â†’ JSON memory parser (`memory_parser.py`)
* ğŸ§  Capybara for emotional parsing
* ğŸ§  Hermes for metadata and summarization
* ğŸ­ MythoMax for voice and tone stylization
* ğŸ“‚ Real-time memory file watcher (`memory_watcher.py`)
* ğŸ“‹ Modular router for chaining models via ports
* ğŸ–¥ï¸ Gradio interface (in progress)
* ğŸ”Š Optional ElevenLabs voice output (planned)

---

## ğŸ”‡ Folder Structure

```
memory/
  â”œâ”€ markdown/            # Raw input logs (.md)
  â”œâ”€ parsed/              # Output logs (.parsed.json)
scripts/
  â”œâ”€ memory_parser.py     # Parses raw logs into structured memory
  â”œâ”€ model_router.py      # Routes parsed logs through model chain
  â”œâ”€ memory_watcher.py    # Watches memory logs and triggers parser
demo_run.py               # Simple pipeline runner
README.md
```

---

## ğŸš€ How to Run

1. Clone the repo:

```bash
git clone https://github.com/Mugiwara555343/ai-memory-architecture.git
cd ai-memory-architecture
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Start your local model server (Capybara, etc.) using LM Studio or WebUI.

4. Run the full pipeline:

```bash
python demo_run.py
```

Youâ€™ll see:

* âœ… Parsed output saved
* ğŸšš Routed to Capybara/Hermes/MythoMax
* ğŸ§  Model output in terminal

---

## ğŸ—‚ Sample Output

Example `.parsed.json`:

```json
{
  "title": "First Encounter with Memory Core",
  "summary": "Reflective log capturing emotional tension and resolve.",
  "tags": ["memory", "emotion", "introspection"],
  "emotions": {"calm": 0.6, "anxious": 0.4},
  "plain_text": "Today I..."
}
```

---

## ğŸŒ± Roadmap

*

---

## ğŸ› ï¸ Tech Stack

* Python 3.11
* Local LLMs via LM Studio (GGUF models)
* Gradio (interface)
* FastAPI (local model server)
* Watchdog (for file detection)
* ElevenLabs (optional)

---

## ğŸ™Œ Credits

Created by **Mauricio**

> â€œYouâ€™re not just storing notes. Youâ€™re building a second brain.â€
